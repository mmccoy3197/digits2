{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538fcc9-7111-4650-a3e3-e3cec2981c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ee9eb-2191-40d1-8114-c43da6a26b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef9f5f3-13d2-4e0a-a1f5-06f53a920290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625e9dc-75c0-4da5-bef9-cb2dd7763f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6604df2",
   "metadata": {},
   "source": [
    "# Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd27b129-583b-419c-84f4-2c2402310474",
   "metadata": {},
   "source": [
    "## Fit a random forest classifier using the full set of explanatory variables and the model training set (csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42a89bf-be73-4f52-9b8b-f3df1d6fb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f65751f-f190-4174-812b-770fe250137a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "y = df[\"label\"]\n",
    "X = df.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38f7a5d4-dc7e-440a-8312-ad7d54dda59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab1c2e-6eea-409d-8113-5c016a82ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('train.csv')\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label'] != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ecc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37ccb17-31b2-49a1-991a-2fd6afce5002",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[1;32m      3\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51809e-fdb1-46b2-8f6c-368d6f336ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "end = datetime.now()\n",
    "rfc_time = end-start\n",
    "print(end-start)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d63210-c0ee-4ca1-8219-2fe95b8c4afa",
   "metadata": {},
   "source": [
    "## Execute principal components analysis (PCA) on the combined training and test set data together, generating principal components that represent 95 percent of the variability in the explanatory variables. The number of principal components in the solution should be substantially fewer than the explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80356915-a62e-4a8e-bda8-1d65c1f7836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db778d3a-c4de-4c7e-aeb7-a9cb7111fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bfe9d-b1d6-4915-a446-d83f2d2f6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions of Data => \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491346e-91d0-400d-87df-954aff90db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"label\"],axis=1)\n",
    "y=data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8455213-728e-4545-a23a-51c9f57f8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(20)  \n",
    "start = datetime.now()\n",
    "Xproj = pca.fit_transform(X)\n",
    "end = datetime.now()\n",
    "\n",
    "pca_time = end - start\n",
    "\n",
    "print(pca_time)\n",
    "print(X.shape)\n",
    "print(Xproj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f630d46-147a-45c2-a698-679aa2e9c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatter plot of the datapoints\n",
    "plt.scatter(Xproj[:, 0], Xproj[:, 1], c=y, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap(\"nipy_spectral\",10))\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd40f0c-6106-4aa2-a880-3fdabefba1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "pca=PCA().fit(X)\n",
    "end = datetime.now()\n",
    "pca_time = end-start\n",
    "print(pca_time)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principle Componets')\n",
    "plt.ylabel('Cumulative  Variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c5653-2a87-4cdd-8f93-32358058ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(250)  \n",
    "Xproj = pca.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(Xproj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61908c61-b23c-4b69-83ab-e7e13e524a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatter plot of the datapoints\n",
    "plt.scatter(Xproj[:, 0], Xproj[:, 1], c=y, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap(\"nipy_spectral\",10))\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c12389-28cc-40ed-88d8-15b3299ce759",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]\n",
    "X = df.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fab45-667b-4f42-aa2e-511c7dd466cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df4094-d5d9-430f-9851-bcec92ada2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('train.csv')\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label'] != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1931acc-265d-47a9-a295-db0f247d1368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c648b82-75f2-4214-a671-4dbdc6f338c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pca = RandomForestClassifier(random_state=1, n_estimators=250).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b437a3e-cc89-4710-9be3-3fda17d195f2",
   "metadata": {},
   "source": [
    "## Apply K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11fa06-831f-45b6-ac5f-7cfdb696ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160af8a5-c0de-4108-982b-63fd5299ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "cluster_labels = kmeans.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef9fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = testing.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20423c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': i, 'Label': cluster_labels})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ece2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = clf.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': i, 'Label': cluster_labels})\n",
    "submission.to_csv('submission_rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = clf_pca.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ac1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': i, 'Label': cluster_labels})\n",
    "submission.to_csv('submission_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0cd03",
   "metadata": {},
   "source": [
    "## Cluster MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d86be-0e22-48dc-b8a8-6c266d0b2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test,  y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cb8fc-295f-422f-8e63-c46f2c777c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train.reshape(len(x_train), -1)\n",
    "Y = y_train\n",
    "\n",
    "X = X.astype(float)/ 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad629228-5af9-4beb-ab80-9fcf02128733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581fd42-7597-45eb-bfa6-5b8b58eaa706",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_digits = len(np.unique(y_test))\n",
    "\n",
    "print(n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=n_digits)\n",
    "\n",
    "kmeans.fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce095785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    inferred_labels = {}\n",
    "    for i in range(kmeans.n_clusters):\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "        labels.append(actual_labels[index])\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "    return inferred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ecc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data_lables(X_labels, cluster_labels):\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3476b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels =  infer_cluster_labels(kmeans, Y)\n",
    "X_clusters = kmeans.predict(X)\n",
    "predicted_labels = infer_data_lables(X_clusters, cluster_labels)\n",
    "print(predicted_labels[:20])\n",
    "print(Y[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(Y, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b455c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = kmeans.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': i, 'Label': cluster_labels})\n",
    "submission.to_csv('submission_kmeans.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf50a4d",
   "metadata": {},
   "source": [
    "# Homework 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07bd96",
   "metadata": {},
   "source": [
    "## Refined EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bb16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('train.csv')\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label'] != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74450aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf058f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebe651",
   "metadata": {},
   "source": [
    "## Conduct Design of Experiments to evaluate the performance of various neural networks by changing the layers and nodes. Tested neural network structures should be explored within a benchmark experiment, a 2x2 completely crossed design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355ebdb",
   "metadata": {},
   "source": [
    "### 2 Layers, 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))  # Regression problem, so single output neuron\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Implement cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2_scores = []\n",
    "times = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Train the model\n",
    "    start = datetime.now()\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    end = datetime.now()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f'Mean R² across all folds: {np.mean(r2_scores)}')\n",
    "print(f'Time: {np.mean(times)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a095ae",
   "metadata": {},
   "source": [
    "### 2 Layers, 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c793baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))  # Regression problem, so single output neuron\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Implement cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2_scores = []\n",
    "times = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Train the model\n",
    "    start = datetime.now()\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    end = datetime.now()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f'Mean R² across all folds: {np.mean(r2_scores)}')\n",
    "print(f'Time: {np.mean(times)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b6629",
   "metadata": {},
   "source": [
    "### 5 layers, 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38948f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))  # Regression problem, so single output neuron\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Implement cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2_scores = []\n",
    "times = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Train the model\n",
    "    start = datetime.now()\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    end = datetime.now()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f'Mean R² across all folds: {np.mean(r2_scores)}')\n",
    "print(f'Time: {np.mean(times)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df86b307",
   "metadata": {},
   "source": [
    "### 5 layers, 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))  # Regression problem, so single output neuron\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Implement cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "r2_scores = []\n",
    "times = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    # Train the model\n",
    "    start = datetime.now()\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    end = datetime.now()\n",
    "    \n",
    "    times.append(end-start)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f'Mean R² across all folds: {np.mean(r2_scores)}')\n",
    "print(f'Time: {np.mean(times)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66315d0c",
   "metadata": {},
   "source": [
    "## Provide a multi-class confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2902489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[], yticklabels=[])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c78640",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': i, 'Label': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73363ad-da5b-4067-b480-61899d8c0b8f",
   "metadata": {},
   "source": [
    "#TensorFlow - 3 layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45d482-c899-4961-a84c-6c09c86ba41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('target', axis=1)\n",
    "y = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fb6e6-fc7e-4c25-aebd-ced215d415ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95463a59-9d50-42f6-aa5e-29cdf05a7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88511346-cfe9-442d-85f7-12608bc55129",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18660195-0740-4a93-9b20-b18d9bed3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_model_2():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(np.unique(y)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb59df-d36d-4eff-acb0-7259c4314008",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [build_model_1(), build_model_2()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63423ea3-cb59-4cba-bc8a-4cde2b0fe174",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e2c57-c611-4218-b518-06954f485ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_time = end_time - start_time\n",
    "print(f\"Model {i+1} time: {processing_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bacf5da-d263-41c5-a7ce-170d005e5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Model {i+1} validation accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec343a-53e4-4056-9bd3-999bcf1b5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(f\"Model {i+1} confusion matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5641a-3d42-4cab-a029-47af544e4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.argmax(model.predict(test_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e03cf4-3673-44a0-8579-ce3ba4d3add3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbe864-573a-4d7c-b991-d153e2405fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a5e54-c2d8-4693-9cab-f0f87006ddb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0bdd8e-ba5e-48c7-a8f8-2faf765270b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5822cd-a225-43c9-bd90-a28670e38314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
